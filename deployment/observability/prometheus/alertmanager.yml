# AlertManager Configuration for Accelerapp
global:
  resolve_timeout: 5m
  # SMTP configuration for email alerts
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@accelerapp.example.com'
  smtp_auth_username: 'alerts@accelerapp.example.com'
  smtp_auth_password: 'changeme'
  smtp_require_tls: true

# Templates for alert notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert routing
route:
  receiver: 'default'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
    
    # High severity alerts
    - match:
        severity: high
      receiver: 'high-priority'
      repeat_interval: 30m
    
    # Warning alerts
    - match:
        severity: warning
      receiver: 'warnings'
      repeat_interval: 1h
    
    # Info alerts
    - match:
        severity: info
      receiver: 'info'
      repeat_interval: 4h

# Inhibition rules to mute alerts
inhibit_rules:
  # Mute warning alerts if critical alerts are firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
  
  # Mute individual alerts if service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']

# Alert receivers
receivers:
  - name: 'default'
    email_configs:
      - to: 'ops-team@accelerapp.example.com'
        headers:
          subject: '[Accelerapp] Alert: {{ .GroupLabels.alertname }}'
    webhook_configs:
      - url: 'http://accelerapp-service:8080/webhooks/alerts'
        send_resolved: true

  - name: 'critical-alerts'
    email_configs:
      - to: 'ops-team@accelerapp.example.com,on-call@accelerapp.example.com'
        headers:
          subject: '[CRITICAL] Accelerapp Alert: {{ .GroupLabels.alertname }}'
    # Slack webhook for critical alerts
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#accelerapp-critical'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    # PagerDuty integration
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
        description: '{{ .GroupLabels.alertname }}: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  - name: 'high-priority'
    email_configs:
      - to: 'ops-team@accelerapp.example.com'
        headers:
          subject: '[HIGH] Accelerapp Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#accelerapp-alerts'
        title: 'High Priority: {{ .GroupLabels.alertname }}'

  - name: 'warnings'
    email_configs:
      - to: 'ops-team@accelerapp.example.com'
        headers:
          subject: '[WARNING] Accelerapp: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#accelerapp-monitoring'

  - name: 'info'
    webhook_configs:
      - url: 'http://accelerapp-service:8080/webhooks/alerts'
        send_resolved: true
